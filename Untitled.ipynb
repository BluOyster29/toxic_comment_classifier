{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_train = train_csv.iloc[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>007bbfa4da2bc32d</td>\n",
       "      <td>Oh, also wouldn't films that are named Three o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>007bc29766a43e3c</td>\n",
       "      <td>Review Request \\n\\nHi,\\n\\nI'd like to request ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>007db1f1477ea977</td>\n",
       "      <td>I don't at all propose that it should be trans...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>007e1e47cd0e2fec</td>\n",
       "      <td>Homosexuals are intent on legitimizing their b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>007ecbb379c4a861</td>\n",
       "      <td>Al Messier \\nThis article was a non-notable bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                       comment_text  \\\n",
       "0    0000997932d777bf  Explanation\\nWhy the edits made under my usern...   \n",
       "1    000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "2    000113f07ec002fd  Hey man, I'm really not trying to edit war. It...   \n",
       "3    0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4    0001d958c54c6e35  You, sir, are my hero. Any chance you remember...   \n",
       "..                ...                                                ...   \n",
       "195  007bbfa4da2bc32d  Oh, also wouldn't films that are named Three o...   \n",
       "196  007bc29766a43e3c  Review Request \\n\\nHi,\\n\\nI'd like to request ...   \n",
       "197  007db1f1477ea977  I don't at all propose that it should be trans...   \n",
       "198  007e1e47cd0e2fec  Homosexuals are intent on legitimizing their b...   \n",
       "199  007ecbb379c4a861  Al Messier \\nThis article was a non-notable bi...   \n",
       "\n",
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0        0             0        0       0       0              0  \n",
       "1        0             0        0       0       0              0  \n",
       "2        0             0        0       0       0              0  \n",
       "3        0             0        0       0       0              0  \n",
       "4        0             0        0       0       0              0  \n",
       "..     ...           ...      ...     ...     ...            ...  \n",
       "195      0             0        0       0       0              0  \n",
       "196      0             0        0       0       0              0  \n",
       "197      0             0        0       0       0              0  \n",
       "198      0             0        0       0       0              0  \n",
       "199      0             0        0       0       0              0  \n",
       "\n",
       "[200 rows x 8 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = toy_train['comment_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_text(text):\n",
    "    return strip_punctuation(' '.join([x.lower() for x in text.split('\\n')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_text(list_texts):\n",
    "    processed_texts = []\n",
    "    for i in list_texts:\n",
    "        flattened = ' '.join([x.lower() for x in i.split('\\n')])\n",
    "        \n",
    "        processed_texts.append(strip_punctuation(flattened))\n",
    "        \n",
    "    return processed_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punctuation(text):\n",
    "    return ''.join([i for i in text if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comments = [flat_text(i) for i in comments]\n",
    "vocab = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_encryptor_decryptor(comments):\n",
    "    for i in comments:\n",
    "        vocab = update_vocab(vocab, i)\n",
    "\n",
    "encryptor, decryptor = gen_vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vocab(vocab, text):\n",
    "    for token in text.split(' '):\n",
    "        if token not in vocab:\n",
    "            vocab.append(token)\n",
    "            \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vocab(vocab):\n",
    "    vocab =  dict(enumerate(vocab))\n",
    "    new_vocab = {num : tok for tok, num in vocab.items()}\n",
    "    return new_vocab, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_text(encryptor, text):\n",
    "    encoded_text = [encryptor[i] for i in text.split(' ')]\n",
    "    return encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = []\n",
    "lengths = []\n",
    "for i in train_comments:\n",
    "    encoded.append(torch.LongTensor(encode_text(encryptor, i)))\n",
    "    lengths.append(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = pad_sequence(encoded, batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = torch.LongTensor(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create label vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for i in range(len(toy_train)):\n",
    "    labels.append(toy_train.iloc[i, 2:].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = pad_sequence(labels, batch_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.LongTensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, input_data, input_labels, input_lengths):\n",
    "        self.input_data = input_data\n",
    "        self.input_labels = input_labels\n",
    "        self.input_lengths = input_lengths\n",
    "    def __getitem__(self, index):\n",
    "        x = self.input_data[index]\n",
    "        y = self.input_labels[index]\n",
    "        z = self.input_lengths[index]\n",
    "        return (x,y, z)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    #define all the layers used in model\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout):\n",
    "        \n",
    "        #Constructor\n",
    "        super().__init__()          \n",
    "        \n",
    "        #embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        #lstm layer\n",
    "        self.lstm = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, \n",
    "                           dropout=dropout,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        #dense layer\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "        #activation function\n",
    "        self.act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        \n",
    "        #text = [batch size,sent_length]\n",
    "        embedded = self.embedding(text)\n",
    "        #embedded = [batch size, sent_len, emb dim]\n",
    "      \n",
    "        #packed sequence\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.lstm(embedded)\n",
    "        #hidden = [batch size, num layers * num directions,hid dim]\n",
    "        #cell = [batch size, num layers * num directions,hid dim]\n",
    "        \n",
    "        #concat the final forward and backward hidden state\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
    "                \n",
    "        #hidden = [batch size, hid dim * num directions]\n",
    "        dense_outputs=self.fc(hidden)\n",
    "\n",
    "        #Final activation function\n",
    "        outputs=self.act(dense_outputs)\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = dataset(encoded, labels, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataloader = DataLoader(training_data, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifier(len(vocab), embedding_dim = 256, hidden_dim = 128, output_dim=6,\n",
    "                  n_layers=2, bidirectional=False, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 1243])\n",
      "torch.Size([50, 6])\n",
      "torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for i in training_dataloader:\n",
    "    x = i[0]\n",
    "    y = i[1]\n",
    "    z = i[2]\n",
    "    out = model(x,z)\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    print(z.shape)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4437, 0.4766, 0.4901, 0.5092, 0.5367, 0.4871],\n",
       "        [0.4485, 0.4763, 0.4910, 0.5074, 0.5369, 0.4841],\n",
       "        [0.4482, 0.4773, 0.4904, 0.5084, 0.5357, 0.4877],\n",
       "        [0.4497, 0.4722, 0.4919, 0.5135, 0.5357, 0.4883],\n",
       "        [0.4479, 0.4814, 0.4915, 0.5034, 0.5377, 0.4845],\n",
       "        [0.4542, 0.4801, 0.4891, 0.5058, 0.5353, 0.4850],\n",
       "        [0.4453, 0.4780, 0.4908, 0.5073, 0.5368, 0.4853],\n",
       "        [0.4493, 0.4769, 0.4873, 0.5055, 0.5385, 0.4864],\n",
       "        [0.4477, 0.4760, 0.4913, 0.5046, 0.5332, 0.4875],\n",
       "        [0.4495, 0.4765, 0.4854, 0.5034, 0.5360, 0.4874],\n",
       "        [0.4489, 0.4730, 0.4884, 0.5054, 0.5371, 0.4869],\n",
       "        [0.4473, 0.4759, 0.4872, 0.5063, 0.5335, 0.4858],\n",
       "        [0.4491, 0.4796, 0.4868, 0.5082, 0.5380, 0.4878],\n",
       "        [0.4500, 0.4795, 0.4884, 0.5061, 0.5353, 0.4903],\n",
       "        [0.4497, 0.4773, 0.4861, 0.5013, 0.5327, 0.4829],\n",
       "        [0.4486, 0.4770, 0.4877, 0.5034, 0.5329, 0.4868],\n",
       "        [0.4479, 0.4821, 0.4889, 0.5060, 0.5335, 0.4889],\n",
       "        [0.4503, 0.4813, 0.4888, 0.5050, 0.5359, 0.4876],\n",
       "        [0.4504, 0.4771, 0.4931, 0.5071, 0.5356, 0.4868],\n",
       "        [0.4481, 0.4778, 0.4891, 0.5042, 0.5374, 0.4891],\n",
       "        [0.4483, 0.4793, 0.4893, 0.5032, 0.5340, 0.4866],\n",
       "        [0.4476, 0.4768, 0.4849, 0.5020, 0.5367, 0.4899],\n",
       "        [0.4479, 0.4816, 0.4876, 0.5068, 0.5381, 0.4935],\n",
       "        [0.4456, 0.4738, 0.4905, 0.5096, 0.5350, 0.4879],\n",
       "        [0.4487, 0.4792, 0.4894, 0.5054, 0.5352, 0.4879],\n",
       "        [0.4476, 0.4800, 0.4862, 0.5056, 0.5365, 0.4884],\n",
       "        [0.4464, 0.4753, 0.4857, 0.5065, 0.5359, 0.4887],\n",
       "        [0.4465, 0.4791, 0.4843, 0.5023, 0.5365, 0.4903],\n",
       "        [0.4499, 0.4746, 0.4878, 0.5048, 0.5349, 0.4897],\n",
       "        [0.4494, 0.4799, 0.4892, 0.5034, 0.5351, 0.4863],\n",
       "        [0.4488, 0.4775, 0.4912, 0.5090, 0.5356, 0.4924],\n",
       "        [0.4496, 0.4757, 0.4890, 0.5075, 0.5328, 0.4870],\n",
       "        [0.4555, 0.4721, 0.4888, 0.5067, 0.5359, 0.4865],\n",
       "        [0.4524, 0.4773, 0.4894, 0.5036, 0.5368, 0.4868],\n",
       "        [0.4533, 0.4782, 0.4835, 0.5058, 0.5343, 0.4849],\n",
       "        [0.4533, 0.4712, 0.4922, 0.5073, 0.5343, 0.4858],\n",
       "        [0.4516, 0.4755, 0.4931, 0.5087, 0.5394, 0.4837],\n",
       "        [0.4487, 0.4760, 0.4916, 0.5059, 0.5379, 0.4883],\n",
       "        [0.4526, 0.4795, 0.4909, 0.5050, 0.5366, 0.4848],\n",
       "        [0.4506, 0.4779, 0.4879, 0.5058, 0.5337, 0.4852],\n",
       "        [0.4459, 0.4773, 0.4872, 0.5087, 0.5383, 0.4888],\n",
       "        [0.4463, 0.4758, 0.4908, 0.5065, 0.5349, 0.4892],\n",
       "        [0.4504, 0.4764, 0.4876, 0.5064, 0.5354, 0.4845],\n",
       "        [0.4487, 0.4767, 0.4873, 0.5059, 0.5354, 0.4843],\n",
       "        [0.4460, 0.4775, 0.4881, 0.5066, 0.5351, 0.4857],\n",
       "        [0.4477, 0.4791, 0.4915, 0.5104, 0.5346, 0.4877],\n",
       "        [0.4505, 0.4780, 0.4898, 0.5051, 0.5395, 0.4876],\n",
       "        [0.4488, 0.4745, 0.4912, 0.5053, 0.5356, 0.4888],\n",
       "        [0.4473, 0.4770, 0.4871, 0.5056, 0.5400, 0.4895],\n",
       "        [0.4485, 0.4755, 0.4893, 0.5096, 0.5352, 0.4876]],\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
